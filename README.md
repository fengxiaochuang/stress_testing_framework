# 压测框架

## 目录文件说明

- **biz** 业务函数, 例如业务中的添加笔录
- **constants** 系统中常用的一些常量定义, 一般不会修改,
 且跨模块的, 如果只是某个模块或者某个文件使用的话, 建议定义在对应的文件中即可
- **core** 核心类, 定义账号, 上下文类以及模板Task父类
- **data** 测试数据
- **logs** 日志文件, 每次执行生成一个新的日志文件夹, 文件夹内一个进程号一个日志
文件, master存储命名为master.log
- **util** 常用工具类, 如果写的比较多的话, 可以单独抽取一个文件聚合, 比较少的
情况下, 直接写在__init__.py的模块入口文件即可
- **app.py** 入口执行程序

## 设计思想
1. 借鉴了web项目的context, 所有的业务测试类都需要把context初始化进去, 
在context中包含了常用的一些信息, 例如: account, token, deadline等,
同时提供了扩展元数据的属性meta, 可以通过set, get, inc等方式修改, 因为所有
的执行任务里面都带有context, 所以也可以通过context在同一个进程中传递参数, 
比如登录的时候把用户信息存入进去, 在其他地方再取出来使用.

2. 通过core.Pipeline子类的run函数定义业务流程, 可以参考pipeline/demo.py文件


## 迁移其他项目使用

1. 删除biz, 并根据自己的业务补全, 每个功能都需要继承core.Task, 并把context初始化进去

2. 根据实际情况判断是否需要每个进程都分配用户, 如果不需要, 则把app.py中的用户随机分配代码修改掉
 
3. 根据pipeline/demo.py文件, 实现一个继承core.Pipeline的类, 把biz中业务汇总即可, 特别要注意写好的pipeline里面异常是否有捕获异常


## 参数配置
参数配置提供三种方式:

### 1. app.py 参数

主要是并发相关的配置: 
并发数: 创建进程池的数量, 如果一个进程分配一个用户的话, 也依赖account.csv的限制

运行时间: 脚本压测时间, 会根据上下文传递到各个任务中, 方便各个任务判断自己的break节点

并发追加速度: 新增并发的速度, 如果设置2秒, 就意味着2秒增加几个新的并发

日志路径: 无需修改
 
### 2. env.yaml 配置

默认读取到环境变量中, 可以很方便的用os.getenv在进程中获取到, 主要是用于业务上面的配置

### 3. account.csv 配置

系统中用到的用户, 理论上应该跟env.yaml放在一起的, 为了修改方便, 单独提出来

读取的时候按用户名去重, 所以添加的时候不允许用户名重复, 否则会以最后一个为准

## Q&A

1. 问: 为什么要用multiprocess多进程的方式

> 为了logging日志打印方便, 通过多进程的方式可以轻松的把不同并发情况下的日志按文件
> 分割并打印保存, 采用系统提供的logging, 基本上第三方组件不用修改, 也都可以兼容
